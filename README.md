# GENET

Reinforcement learning resources for the Performance-oriented Congestion Control
project.

## Installation and Setup

- Run the following command to clone the repo.

    ```bash
    git clone git@github.com:zxxia/PCC-RL.git
    ```

- Virtual environment is highly recommended. Please set up one in python3. FYI,
  [venv](https://docs.python.org/3.7/library/venv.html) and
  [conda](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).
  Other virtual environment related tools are like
  [virtualenvwrapper](https://virtualenvwrapper.readthedocs.io/en/latest/),
  [pyenv](https://github.com/pyenv/pyenv) and, etc.
- Activate the virtual environment.
- Run the following commands to install the required packges.

  - For Ubuntu

    ```bash
    cd PCC-RL
    sudo apt install mpich
    pip install -r requirements.txt
    ```

- Add `src` to `$PYTHONPATH` by running

    ```bash
    cd PCC-RL
    export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
    ```
  <!--  -->
  <!-- - For MacOS -->
  <!--  -->
  <!--   ```bash -->
  <!--   cd PCC-RL -->
  <!--   brew install openmpi -->
  <!--   pip install -r requirements.txt -->
  <!--   ``` -->

## Traces

### Real Traces

Real traces are recorded on Pantheon platform and they can be downloaded from
[Pantheon](https://pantheon.stanford.edu/measurements/node/). There are three
connection types: cellular, ethernet, and wifi. The path to store them is
`PCC-RL/data/${connection_type}`

### Syntheic Traces

Generated by `PCC-RL/src/simulator/trace.py`

## Configuration files

The configurations are stored at `PCC-RL/config/train`

## Training

### udr training

```bash
cd src/simulator
# run on CPU only if CUDA & GPU(s) are installed and use 2 workers
CUDA_VISIBLE_DEVICES="" mpiexec -np 2 python train_rl.py \
    --save-dir ${save_dir} \
    --total-timesteps 1000000 \
    --randomization-range-file ${path_to_config_file} \
    --seed ${seed} \
    --pretrained-model-path ${path_to_pretrained_model}
```

### genet training

```bash
cd src/simulator
CUDA_VISIBLE_DEVICES="" python genet_improved.py \
    --seed ${seed} \
    --heuristic ${rule_based_method_name} \
    --save-dir ${save_dir}/ \
    --config-file ${path_to_config_file} \
    --bo-rounds ${n_bo} \
    --model-path ${path_to_pretrained_model}
```

### Rule-based baselines

- BBR: [paper](https://www.cis.upenn.edu/~cis553/files/BBR.pdf),
  [code](https://github.com/google/bbr),
  [implentation in simulator](src/simulator/network_simulator/bbr.py)
- Copa:
  [paper](https://www.usenix.org/system/files/conference/nsdi18/nsdi18-arun.pdf),
  [code](https://github.com/venkatarun95/genericCC)
- Cubic:
  [paper](https://www.cs.princeton.edu/courses/archive/fall16/cos561/papers/Cubic08.pdf),
  [code](https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next.git/tree/net/ipv4/tcp_cubic.c),
  [implentation in simulator](src/simulator/network_simulator/cubic.py)
- PCC-Vivace:
  [paper](https://www.usenix.org/system/files/conference/nsdi18/nsdi18-dong.pdf),
  [code](https://github.com/PCCproject/PCC-Uspace),
  [implentation in simulator](src/simulator/network_simulator/pcc/vivace/vivace_latency.py)

<!-- ## Overview -->
<!--  -->
<!-- This repo contains the gym environment required for training reinforcement -->
<!-- learning models used in the PCC project along with the Python module required to -->
<!-- run RL models in the PCC UDT codebase found at github.com/PCCProject/PCC-Uspace. -->
<!--  -->
<!--  -->
<!-- ## Training -->
<!-- To run training only, go to ./src/gym/, install any missing requirements for -->
<!-- stable\_solve.py and run that script. By default, this should replicate the -->
<!-- model presented in A Reinforcement Learning Perspective on Internet Congestion -->
<!-- Control, ICML 2019. -->
<!--  -->
<!-- ## Testing Models -->
<!--  -->
<!-- To test models in the real world (i.e., sending real packets into the Linux -->
<!-- kernel and out onto a real or emulated network), download and install the PCC -->
<!-- UDT code from github.com/PCCProject/PCC-Uspace. Follow the instructions in that -->
<!-- repo for using congestion control algorithms with Python modules, and see -->
<!-- ./src/gym/online/README.md for additional instructions regarding testing or training models in the real world. -->
